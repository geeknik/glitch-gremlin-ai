import * as tf from '@tensorflow/tfjs-node';
import { EventEmitter } from 'events';
import { Logger } from '@/utils/logger';

export enum VulnerabilityType {
    Reentrancy = 'REENTRANCY',
    ArithmeticOverflow = 'ARITHMETIC_OVERFLOW',
    AccessControl = 'ACCESS_CONTROL',
    DenialOfService = 'DENIAL_OF_SERVICE',
    LogicError = 'LOGIC_ERROR',
    InstructionInjection = 'INSTRUCTION_INJECTION',
    AccountConfusion = 'ACCOUNT_CONFUSION',
    SignerAuthorization = 'SIGNER_AUTHORIZATION',
    PdaValidation = 'PDA_VALIDATION',
    ClockManipulation = 'CLOCK_MANIPULATION',
    CrossProgramInvocation = 'CROSS_PROGRAM_INVOCATION',
    RentExemption = 'RENT_EXEMPTION',
    AccountDataMatching = 'ACCOUNT_DATA_MATCHING',
    AccountReloading = 'ACCOUNT_RELOADING',
    ArbitraryCpi = 'ARBITRARY_CPI',
    AuthorityTransfer = 'AUTHORITY_TRANSFER',
    BumpSeedCanonicalization = 'BUMP_SEED_CANONICALIZATION',
    AccountClosing = 'ACCOUNT_CLOSING',
    DuplicateMutableAccounts = 'DUPLICATE_MUTABLE_ACCOUNTS',
    Frontrunning = 'FRONTRUNNING',
    InsecureInitialization = 'INSECURE_INITIALIZATION',
    PdaSharing = 'PDA_SHARING',
    RemainingAccountsValidation = 'REMAINING_ACCOUNTS_VALIDATION',
    RustSpecificError = 'RUST_SPECIFIC_ERROR',
    SeedCollision = 'SEED_COLLISION',
    TypeCosplay = 'TYPE_COSPLAY'
}

export interface VulnerabilityPrediction {
    type: VulnerabilityType | null;
    confidence: number;
    details: string[];
}

interface TrainingCallback extends tf.CustomCallback {
    onEpochEnd: (epoch: number, logs?: { loss: number; accuracy: number }) => Promise<void>;
}


// Helper function to generate training data for testing
export function generateTrainingData(size: number = 10) {
    return Array.from({ length: size }, (_, i) => ({
        features: Array.from({ length: 50 }, (_, j) => {
            // Generate Solana-specific patterns
            const basePattern = Math.sin(i * j) * 0.5 + Math.random() * 0.5;
            
            // Add Solana-specific feature patterns
            if (j < 10) {
                // Account validation patterns
                return basePattern * (1 + Math.cos(j * Math.PI / 5));
            } else if (j < 20) {
                // PDA and seed patterns
                return basePattern * (1 + Math.sin(j * Math.PI / 10));
            } else if (j < 30) {
                // CPI and authorization patterns
                return basePattern * (1 + Math.tan(j * Math.PI / 20));
            } else if (j < 40) {
                // Instruction validation patterns
                return basePattern * (1 + Math.sin(j * Math.PI / 15));
            } else {
                // Program state patterns
                return basePattern * (1 + Math.cos(j * Math.PI / 25));
            }
        }),
        vulnerabilityType: Object.values(VulnerabilityType)[i % Object.keys(VulnerabilityType).length]
    }));
}

export class VulnerabilityDetectionModel extends EventEmitter {
    private model: tf.LayersModel | null = null;
    private logger: Logger;

    private readonly modelEvents = {
        trainingStart: 'trainingStart',
        epochEnd: 'epochEnd',
    } as const;

    constructor() {
        super();
        this.logger = new Logger('VulnerabilityDetection');
    }

    async train(data: { features: number[]; vulnerabilityType: VulnerabilityType }[]): Promise<void> {
        this.emit('trainingStart');
        this.logger.info('Starting model training');
        if (!data || data.length === 0) {
            throw new Error('Training data cannot be empty');
        }
        
        // Validate feature dimensions consistency
        const featureLength = data[0].features.length;
        if (!data.every(d => d.features.length === featureLength)) {
            throw new Error(`Inconsistent feature dimensions. Expected ${featureLength} features for all inputs`);
        }
        
        // Validate feature types
        if (!data.every(d => d.features.every(f => typeof f === 'number' && !isNaN(f)))) {
            throw new Error('Invalid feature values. All features must be valid numbers');
        }
        
        // Validate vulnerability types
        if (!data.every(d => Object.values(VulnerabilityType).includes(d.vulnerabilityType))) {
            throw new Error('Invalid vulnerability type detected');
        }

        try {
            // Convert data to tensors
            const features = data.map(d => d.features);
            const labels = data.map(d => d.vulnerabilityType);

            // Normalize features
            const xs = tf.tensor2d(features);
            const normalizedXs = tf.div(xs, tf.max(xs));

            // One-hot encode labels
            const ys = tf.oneHot(
                tf.tensor1d(labels, 'int32'), 
                Object.keys(VulnerabilityType).length
            );

            // Simplified model architecture with dense layers
            const model = tf.sequential();

            // Enhanced input layer for Solana-specific patterns
            model.add(tf.layers.dense({
                units: 512,
                activation: 'swish',
                inputShape: [features[0].length],
                kernelRegularizer: tf.regularizers.l1l2({ l1: 0.01, l2: 0.01 })
            }));
            model.add(tf.layers.batchNormalization());

            // Specialized layers for Solana security patterns
            const accountPatternBranch = tf.layers.dense({
                units: 256,
                activation: 'relu',
                kernelRegularizer: tf.regularizers.l1l2({ l1: 0.01, l2: 0.01 })
            });
            model.add(accountPatternBranch);
            model.add(tf.layers.batchNormalization());

            // PDA and seed validation branch
            model.add(tf.layers.dropout({ rate: 0.4 }));
            model.add(tf.layers.dense({
                units: 192,
                activation: 'selu',
                kernelRegularizer: tf.regularizers.l1l2({ l1: 0.01, l2: 0.01 })
            }));
            model.add(tf.layers.batchNormalization());

            // CPI and authorization pattern detection
            model.add(tf.layers.dropout({ rate: 0.4 }));
            model.add(tf.layers.dense({
                units: 128,
                activation: 'elu',
                kernelRegularizer: tf.regularizers.l1l2({ l1: 0.01, l2: 0.01 })
            }));

            // Program state validation layers
            model.add(tf.layers.dropout({ rate: 0.4 }));
            model.add(tf.layers.dense({
                units: 96,
                activation: 'relu',
                kernelRegularizer: tf.regularizers.l1l2({ l1: 0.01, l2: 0.01 })
            }));

            // Feature fusion layer
            model.add(tf.layers.dropout({ rate: 0.4 }));
            model.add(tf.layers.dense({
                units: 64,
                activation: 'swish',
                kernelRegularizer: tf.regularizers.l1l2({ l1: 0.01, l2: 0.01 })
            }));

            // Output layer with temperature scaling
            model.add(tf.layers.dense({
                units: Object.keys(VulnerabilityType).length,
                activation: 'softmax',
                kernelInitializer: 'glorotUniform',
                biasInitializer: 'zeros'
            }));

            // Compile with custom optimizer and metrics
            const optimizer = tf.train.adam(0.0005, 0.9, 0.999, 1e-7);
            model.compile({
                optimizer,
                loss: 'categoricalCrossentropy',
                metrics: [
                    'accuracy',
                    tf.metrics.precision,
                    tf.metrics.recall,
                    'AUC'
                ]
            });

            // Enhanced training with more callbacks
            await model.fit(normalizedXs, ys, {
                epochs: 150,
                batchSize: 32,
                validationSplit: 0.2,
                callbacks: [
                    tf.callbacks.earlyStopping({
                        monitor: 'val_loss',
                        patience: 15,
                        minDelta: 0.001,
                        verbose: 1
                    }),
                    {
                        onEpochEnd: async (epoch: number, logs?: { loss: number; accuracy: number }): Promise<void> => {
                            this.emit(this.modelEvents.epochEnd, { epoch, logs });
                            if (logs) {
                                this.logger.info(`Epoch ${epoch} - loss: ${logs.loss.toFixed(4)}, accuracy: ${logs.accuracy.toFixed(4)}`);
                            }
                            return Promise.resolve();
                        }
                    }
                ]
            });

            // Evaluate model
            // Final model evaluation
            const evaluation = model.evaluate(normalizedXs, ys);
            if (Array.isArray(evaluation)) {
                try {
                    const [loss, accuracy, precision, recall, auc] = evaluation;
                    this.logger.info('Training complete with metrics:');
                    this.logger.info(`Loss: ${loss.dataSync()[0].toFixed(4)}`);
                    this.logger.info(`Accuracy: ${accuracy.dataSync()[0].toFixed(4)}`);
                    this.logger.info(`Precision: ${precision.dataSync()[0].toFixed(4)}`);
                    this.logger.info(`Recall: ${recall.dataSync()[0].toFixed(4)}`);
                    this.logger.info(`AUC: ${auc.dataSync()[0].toFixed(4)}`);
                } finally {
                    // Ensure tensors are disposed even if dataSync throws
                    evaluation.forEach(tensor => tensor.dispose());
                }
            }

            this.model = model;

            // Clean up tensors
            xs.dispose();
            normalizedXs.dispose();
            ys.dispose();
        } catch (error) {
            // Clean up tensors before throwing
            try {
                xs.dispose();
                normalizedXs.dispose();
                ys.dispose();
            } catch (cleanupError) {
                this.logger.error(`Error during tensor cleanup: ${(cleanupError as Error).message}`);
            }
            
            const errorMessage = error instanceof Error ? error.message : 'Unknown error occurred';
            this.logger.error(`Model training failed: ${errorMessage}`);
            throw new Error(`Training failed: ${errorMessage}. Please check input data and model configuration.`);
        }
    }

    async predict(features: number[]): Promise<VulnerabilityPrediction> {
        if (!this.model) {
            throw new Error('Model not trained');
        }

        // Validate input features
        if (!features || !Array.isArray(features)) {
            throw new Error('Invalid features array provided');
        }

        // Perform Solana-specific security pattern analysis
        const securityPatterns = await this.analyzeSolanaSecurityPatterns(features);
        const correlationResults = this.analyzeVulnerabilityCorrelations(securityPatterns);
        
        let input: tf.Tensor2D | null = null;
        let prediction: tf.Tensor | null = null;
        let normalizedInput: tf.Tensor2D | null = null;

        try {
            // Normalize input features
            input = tf.tensor2d([features]);
            normalizedInput = tf.div(input, tf.max(input));
            
            // Get prediction with confidence adjustment
            prediction = this.model.predict(normalizedInput) as tf.Tensor;
            const values = await prediction.data();

            // Apply severity-based confidence thresholds
            const adjustedValues = this.adjustConfidenceThresholds(Array.from(values));

            // Get predictions above threshold
            const significantVulnerabilities = this.identifySignificantVulnerabilities(adjustedValues);

            // Get primary vulnerability
            const maxIndex = adjustedValues.indexOf(Math.max(...adjustedValues));
            const type = Object.values(VulnerabilityType)[maxIndex] || null;
            const confidence = adjustedValues[maxIndex];

            // Generate comprehensive analysis
            const details = [
                ...this.getDetails(type, features),
                ...this.generateSecurityRecommendations(significantVulnerabilities),
                ...this.correlationAnalysis(correlationResults)
            ];

            return {
                type,
                confidence,
                details
            };
        } catch (error) {
            this.logger.error(`Prediction failed: ${(error as Error).message}`);
            throw new Error(`Prediction failed: ${(error as Error).message}`); 
        } finally {
            // Ensure all tensors are disposed
            if (input) input.dispose();
            if (prediction) prediction.dispose();
            if (normalizedInput) normalizedInput.dispose();
        }
    }

    private async analyzeSolanaSecurityPatterns(features: number[]): Promise<any> {
        const patterns = {
            accountValidation: features.slice(0, 10),
            pdaHandling: features.slice(10, 20),
            cpiSecurity: features.slice(20, 30),
            stateConsistency: features.slice(30, 40),
            privilegeEscalation: features.slice(40, 50)
        };

        return {
            riskScores: {
                accountValidation: this.calculateRiskScore(patterns.accountValidation),
                pdaHandling: this.calculateRiskScore(patterns.pdaHandling),
                cpiSecurity: this.calculateRiskScore(patterns.cpiSecurity),
                stateConsistency: this.calculateRiskScore(patterns.stateConsistency),
                privilegeEscalation: this.calculateRiskScore(patterns.privilegeEscalation)
            },
            anomalyDetection: this.detectAnomalousPatterns(patterns)
        };
    }

    private calculateRiskScore(features: number[]): number {
        return features.reduce((acc, val) => acc + Math.pow(val, 2), 0) / features.length;
    }

    private detectAnomalousPatterns(patterns: any): any {
        const anomalies = {};
        for (const [category, values] of Object.entries(patterns)) {
            const mean = (values as number[]).reduce((acc, val) => acc + val, 0) / values.length;
            const stdDev = Math.sqrt(
                (values as number[]).reduce((acc, val) => acc + Math.pow(val - mean, 2), 0) / values.length
            );
            anomalies[category] = (values as number[]).filter(val => Math.abs(val - mean) > 2 * stdDev);
        }
        return anomalies;
    }

    private analyzeVulnerabilityCorrelations(securityPatterns: any): any {
        const correlations = {};
        const patterns = securityPatterns.riskScores;
        
        for (const type1 of Object.keys(patterns)) {
            correlations[type1] = {};
            for (const type2 of Object.keys(patterns)) {
                if (type1 !== type2) {
                    correlations[type1][type2] = this.calculateCorrelation(
                        patterns[type1],
                        patterns[type2]
                    );
                }
            }
        }
        
        return correlations;
    }

    private calculateCorrelation(x: number, y: number): number {
        return Math.abs(x - y) < 0.3 ? "High" : Math.abs(x - y) < 0.6 ? "Medium" : "Low";
    }

    private adjustConfidenceThresholds(values: number[]): number[] {
        const severityWeights = {
            [VulnerabilityType.ArbitraryCpi]: 1.2,
            [VulnerabilityType.SignerAuthorization]: 1.15,
            [VulnerabilityType.PdaValidation]: 1.1,
            [VulnerabilityType.AccountDataMatching]: 1.05
        };

        return values.map((value, index) => {
            const vulnType = Object.values(VulnerabilityType)[index];
            return value * (severityWeights[vulnType] || 1.0);
        });
    }

    private identifySignificantVulnerabilities(values: number[]): any[] {
        const significantThreshold = 0.3;
        return values
            .map((value, index) => ({
                type: Object.values(VulnerabilityType)[index],
                confidence: value
            }))
            .filter(v => v.confidence > significantThreshold);
    }

    private generateSecurityRecommendations(vulnerabilities: any[]): string[] {
        const recommendations = [];
        for (const vuln of vulnerabilities) {
            recommendations.push(...this.getVulnerabilitySpecificRecommendations(vuln.type));
        }
        return recommendations;
    }

    private getVulnerabilitySpecificRecommendations(type: VulnerabilityType): string[] {
        const recommendations = {
            [VulnerabilityType.ArbitraryCpi]: [
                'Implement strict CPI target validation',
                'Use program address validation helpers',
                'Add checksums for expected programs'
            ],
            [VulnerabilityType.PdaValidation]: [
                'Validate all PDA seeds and bump seeds',
                'Use canonical bump derivation',
                'Implement seed validation helpers'
            ]
        };
        return recommendations[type] || [];
    }

    private correlationAnalysis(correlations: any): string[] {
        const analysis = [];
        for (const [type1, correlationData] of Object.entries(correlations)) {
            for (const [type2, correlation] of Object.entries(correlationData)) {
                if (correlation === "High") {
                    analysis.push(
                        `High correlation detected between ${type1} and ${type2} vulnerabilities. ` +
                        'Consider implementing joint mitigation strategies.'
                    );
                }
            }
        }
        return analysis;
    }

    private getDetails(type: VulnerabilityType | null, features: number[]): string[] {
        const details: string[] = [];
        
        if (!type) {
            return ['No significant vulnerabilities detected'];
        }

        // Feature importance mapping
        const featureMapping = {
            [VulnerabilityType.Reentrancy]: {
                index: 0,
                threshold: 0.8,
                message: 'High reentrancy risk detected'
            },
            [VulnerabilityType.ArithmeticOverflow]: {
                index: 1,
                threshold: 0.7,
                message: 'Potential arithmetic overflow detected'
            },
            [VulnerabilityType.AccessControl]: {
                index: 2,
                threshold: 0.75,
                message: 'Access control violation detected'
            },
            [VulnerabilityType.DenialOfService]: {
                index: 3,
                threshold: 0.85,
                message: 'Potential denial of service vulnerability detected'
            },
            [VulnerabilityType.LogicError]: {
                index: 4,
                threshold: 0.8,
                message: 'Logic error detected'
            },
            [VulnerabilityType.InstructionInjection]: {
                index: 5,
                threshold: 0.85,
                message: 'Instruction injection vulnerability detected'
            },
            [VulnerabilityType.AccountConfusion]: {
                index: 6,
                threshold: 0.8,
                message: 'Potential account confusion detected'
            },
            [VulnerabilityType.SignerAuthorization]: {
                index: 7,
                threshold: 0.85,
                message: 'Signer authorization issue detected'
            },
            [VulnerabilityType.PdaValidation]: {
                index: 8,
                threshold: 0.8,
                message: 'PDA validation issue detected'
            },
            [VulnerabilityType.ClockManipulation]: {
                index: 9,
                threshold: 0.85,
                message: 'Clock manipulation vulnerability detected'
            },
            [VulnerabilityType.CrossProgramInvocation]: {
                index: 10,
                threshold: 0.85,
                message: 'Cross-program invocation vulnerability detected'
            },
            [VulnerabilityType.RentExemption]: {
                index: 11,
                threshold: 0.8,
                message: 'Rent exemption issue detected'
            },
            [VulnerabilityType.AccountDataMatching]: {
                index: 12,
                threshold: 0.8,
                message: 'Account data does not match expected values'
            },
            [VulnerabilityType.AccountReloading]: {
                index: 13,
                threshold: 0.85,
                message: 'Account not reloaded after CPI, potential stale data'
            },
            [VulnerabilityType.ArbitraryCpi]: {
                index: 14,
                threshold: 0.9,
                message: 'Potential arbitrary cross-program invocation detected'
            },
            [VulnerabilityType.AuthorityTransfer]: {
                index: 15,
                threshold: 0.85,
                message: 'Insecure authority transfer mechanism detected'
            },
            [VulnerabilityType.BumpSeedCanonicalization]: {
                index: 16,
                threshold: 0.8,
                message: 'Non-canonical bump seed usage detected'
            },
            [VulnerabilityType.AccountClosing]: {
                index: 17,
                threshold: 0.85,
                message: 'Improper account closing procedure detected'
            },
            [VulnerabilityType.DuplicateMutableAccounts]: {
                index: 18,
                threshold: 0.9,
                message: 'Duplicate mutable account references detected'
            },
            [VulnerabilityType.Frontrunning]: {
                index: 19,
                threshold: 0.85,
                message: 'Potential frontrunning vulnerability detected'
            },
            [VulnerabilityType.InsecureInitialization]: {
                index: 20,
                threshold: 0.85,
                message: 'Insecure initialization pattern detected'
            },
            [VulnerabilityType.PdaSharing]: {
                index: 21,
                threshold: 0.8,
                message: 'Unsafe PDA sharing pattern detected'
            },
            [VulnerabilityType.RemainingAccountsValidation]: {
                index: 22,
                threshold: 0.85,
                message: 'Insufficient validation of remaining accounts'
            },
            [VulnerabilityType.RustSpecificError]: {
                index: 23,
                threshold: 0.8,
                message: 'Rust-specific security issue detected'
            },
            [VulnerabilityType.SeedCollision]: {
                index: 24,
                threshold: 0.85,
                message: 'Potential PDA seed collision vulnerability'
            },
            [VulnerabilityType.TypeCosplay]: {
                index: 25,
                threshold: 0.9,
                message: 'Account type verification bypass detected'
            }
        };

        const typeDetails = type ? featureMapping[type] : undefined;
        if (typeDetails && features[typeDetails.index] > typeDetails.threshold) {
            details.push(typeDetails.message);
        }

        // Generate detailed remediation steps based on vulnerability type
        if (type) {
            details.push('Detailed Remediation Steps:');
            switch (type) {
                case VulnerabilityType.ArbitraryCpi:
                    details.push('- Implement strict program ID validation');
                    details.push('- Use a whitelist of allowed program IDs');
                    details.push('- Validate CPI call parameters');
                    details.push('- Implement proper error handling for CPI failures');
                    break;
                case VulnerabilityType.PdaValidation:
                    details.push('- Verify all PDA seeds match expected values');
                    details.push('- Use canonical bump derivation');
                    details.push('- Implement PDA ownership validation');
                    details.push('- Add checks for PDA account data consistency');
                    break;
                case VulnerabilityType.AccountDataMatching:
                    details.push('- Validate account data types and sizes');
                    details.push('- Implement strong deserialization checks');
                    details.push('- Add owner program validation');
                    details.push('- Verify account relationships');
                    break;
                // Add more specific remediation steps for other vulnerability types
            }
        }

        // Add enhanced security recommendations
        details.push('\nSecurity Best Practices:');
        details.push('- Review program instructions for potential vulnerabilities');
        details.push('- Implement proper access control checks');
        details.push('- Validate all account inputs and ensure proper typing');
        details.push('- Use safe arithmetic operations and check for overflows');
        details.push('- Implement comprehensive testing across different scenarios');
        details.push('- Add proper error handling and logging');

        return details;
    }

    async save(path: string): Promise<void> {
        if (!this.model) {
            throw new Error('Model not trained');
        }
        
        if (!path || typeof path !== 'string') {
            throw new Error('Invalid save path specified');
        }

        try {
            await this.model.save(`file://${path}`);
            this.logger.info(`Model saved successfully to ${path}`);
        } catch (error) {
            const errorMessage = error instanceof Error ? error.message : 'Unknown error';
            throw new Error(`Failed to save model: ${errorMessage}`);
        }
    }

    async load(path: string): Promise<void> {
        if (!path || typeof path !== 'string') {
            throw new Error('Invalid model path specified');
        }

        try {
            // Cleanup existing model if any
            if (this.model) {
                this.model.dispose();
            }

            this.model = await tf.loadLayersModel(`file://${path}/model.json`);
            
            // Validate loaded model structure
            if (!this.model || !this.model.inputs || !this.model.inputs[0]) {
                throw new Error('Invalid model structure detected after load');
            }

            this.logger.info(`Model loaded successfully from ${path}`);
        } catch (error) {
            const errorMessage = error instanceof Error ? error.message : 'Unknown error';
            throw new Error(`Failed to load model: ${errorMessage}`);
        }
    }

    async cleanup(): Promise<void> {
        try {
            // Dispose model and layers
            if (this.model) {
                // Dispose each layer
                this.model.layers.forEach(layer => {
                    if (layer.weights) {
                        layer.weights.forEach(w => w.dispose());
                    }
                });
                
                // Dispose model
                this.model.dispose();
                this.model = null;
            }
            
            // Dispose any remaining variables and tensors
            await tf.disposeVariables();
            
            // Force garbage collection of tensors
            const backend = tf.getBackend();
            if (backend === 'webgl') {
                const gl = await tf.backend().getGPGPUContext().gl;
                gl.getExtension('WEBGL_lose_context')?.loseContext();
            }
            
            this.logger.info('Model cleanup completed successfully');
        } catch (error) {
            const errorMessage = error instanceof Error ? error.message : 'Unknown error during cleanup';
            this.logger.error(`Cleanup failed: ${errorMessage}`);
            throw new Error(`Cleanup failed: ${errorMessage}`);
        }
        
        // Verify cleanup
        if (tf.memory().numTensors > 0) {
            this.logger.warn(`${tf.memory().numTensors} tensors still in memory after cleanup`);
        }
    }
}
