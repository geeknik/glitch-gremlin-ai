import * as tf from '@tensorflow/tfjs-node';
import { EventEmitter } from 'events';
import { Logger } from '@/utils/logger';

export enum VulnerabilityType {
    Reentrancy = 'REENTRANCY',
    ArithmeticOverflow = 'ARITHMETIC_OVERFLOW',
    AccessControl = 'ACCESS_CONTROL',
    DenialOfService = 'DENIAL_OF_SERVICE',
    LogicError = 'LOGIC_ERROR',
    InstructionInjection = 'INSTRUCTION_INJECTION',
    AccountConfusion = 'ACCOUNT_CONFUSION',
    SignerAuthorization = 'SIGNER_AUTHORIZATION',
    PdaValidation = 'PDA_VALIDATION',
    ClockManipulation = 'CLOCK_MANIPULATION',
    CrossProgramInvocation = 'CROSS_PROGRAM_INVOCATION',
    RentExemption = 'RENT_EXEMPTION'
}

export interface VulnerabilityPrediction {
    type: VulnerabilityType | null;
    confidence: number;
    details: string[];
}

interface TrainingCallback extends tf.CustomCallback {
    onEpochEnd: (epoch: number, logs?: { loss: number; accuracy: number }) => Promise<void>;
}


// Helper function to generate training data for testing
export function generateTrainingData(size: number = 10) {
    return Array.from({ length: size }, (_, i) => ({
        features: Array.from({ length: 20 }, (_, j) => 
            // Generate diverse feature patterns
            Math.sin(i * j) * 0.5 + Math.random() * 0.5
        ),
        vulnerabilityType: Object.values(VulnerabilityType)[i % Object.keys(VulnerabilityType).length]
    }));
}

export class VulnerabilityDetectionModel extends EventEmitter {
    private model: tf.LayersModel | null = null;
    private logger: Logger;

    private readonly modelEvents = {
        trainingStart: 'trainingStart',
        epochEnd: 'epochEnd',
    } as const;

    constructor() {
        super();
        this.logger = new Logger('VulnerabilityDetection');
    }

    async train(data: { features: number[]; vulnerabilityType: VulnerabilityType }[]): Promise<void> {
        this.emit('trainingStart');
        this.logger.info('Starting model training');
        if (!data || data.length === 0) {
            throw new Error('Training data cannot be empty');
        }
        
        // Validate feature dimensions consistency
        const featureLength = data[0].features.length;
        if (!data.every(d => d.features.length === featureLength)) {
            throw new Error(`Inconsistent feature dimensions. Expected ${featureLength} features for all inputs`);
        }
        
        // Validate feature types
        if (!data.every(d => d.features.every(f => typeof f === 'number' && !isNaN(f)))) {
            throw new Error('Invalid feature values. All features must be valid numbers');
        }
        
        // Validate vulnerability types
        if (!data.every(d => Object.values(VulnerabilityType).includes(d.vulnerabilityType))) {
            throw new Error('Invalid vulnerability type detected');
        }

        try {
            // Convert data to tensors
            const features = data.map(d => d.features);
            const labels = data.map(d => d.vulnerabilityType);

            // Normalize features
            const xs = tf.tensor2d(features);
            const normalizedXs = tf.div(xs, tf.max(xs));

            // One-hot encode labels
            const ys = tf.oneHot(
                tf.tensor1d(labels, 'int32'), 
                Object.keys(VulnerabilityType).length
            );

            // Simplified model architecture with dense layers
            const model = tf.sequential();
            
            // Input layer with batch normalization
            model.add(tf.layers.dense({
                units: 256,
                activation: 'relu',
                inputShape: [features[0].length],
                kernelRegularizer: tf.regularizers.l2({ l2: 0.01 })
            }));
            model.add(tf.layers.batchNormalization());
            
            // Dense layers with dropout for feature extraction
            model.add(tf.layers.dropout({ rate: 0.3 }));
            model.add(tf.layers.dense({
                units: 128,
                activation: 'relu',
                kernelRegularizer: tf.regularizers.l2({ l2: 0.01 })
            }));
            
            model.add(tf.layers.dropout({ rate: 0.3 }));
            model.add(tf.layers.dense({
                units: 64,
                activation: 'relu',
                kernelRegularizer: tf.regularizers.l2({ l2: 0.01 })
            }));

            model.add(tf.layers.dropout({ rate: 0.3 }));
            model.add(tf.layers.dense({
                units: 32,
                activation: 'relu'
            }));

            // Output layer with temperature scaling
            model.add(tf.layers.dense({
                units: Object.keys(VulnerabilityType).length,
                activation: 'softmax',
                kernelInitializer: 'glorotUniform',
                biasInitializer: 'zeros'
            }));

            // Compile with custom optimizer and metrics
            const optimizer = tf.train.adam(0.0005, 0.9, 0.999, 1e-7);
            model.compile({
                optimizer,
                loss: 'categoricalCrossentropy',
                metrics: [
                    'accuracy',
                    tf.metrics.precision,
                    tf.metrics.recall,
                    'AUC'
                ]
            });

            // Enhanced training with more callbacks
            await model.fit(normalizedXs, ys, {
                epochs: 150,
                batchSize: 32,
                validationSplit: 0.2,
                callbacks: [
                    tf.callbacks.earlyStopping({
                        monitor: 'val_loss',
                        patience: 15,
                        minDelta: 0.001,
                        verbose: 1
                    }),
                    {
                        onEpochEnd: async (epoch: number, logs?: { loss: number; accuracy: number }): Promise<void> => {
                            this.emit(this.modelEvents.epochEnd, { epoch, logs });
                            if (logs) {
                                this.logger.info(`Epoch ${epoch} - loss: ${logs.loss.toFixed(4)}, accuracy: ${logs.accuracy.toFixed(4)}`);
                            }
                            return Promise.resolve();
                        }
                    }
                ]
            });

            // Evaluate model
            // Final model evaluation
            const evaluation = model.evaluate(normalizedXs, ys);
            if (Array.isArray(evaluation)) {
                try {
                    const [loss, accuracy, precision, recall, auc] = evaluation;
                    this.logger.info('Training complete with metrics:');
                    this.logger.info(`Loss: ${loss.dataSync()[0].toFixed(4)}`);
                    this.logger.info(`Accuracy: ${accuracy.dataSync()[0].toFixed(4)}`);
                    this.logger.info(`Precision: ${precision.dataSync()[0].toFixed(4)}`);
                    this.logger.info(`Recall: ${recall.dataSync()[0].toFixed(4)}`);
                    this.logger.info(`AUC: ${auc.dataSync()[0].toFixed(4)}`);
                } finally {
                    // Ensure tensors are disposed even if dataSync throws
                    evaluation.forEach(tensor => tensor.dispose());
                }
            }

            this.model = model;

            // Clean up tensors
            xs.dispose();
            normalizedXs.dispose();
            ys.dispose();
        } catch (error) {
            // Clean up tensors before throwing
            try {
                xs.dispose();
                normalizedXs.dispose();
                ys.dispose();
            } catch (cleanupError) {
                this.logger.error(`Error during tensor cleanup: ${(cleanupError as Error).message}`);
            }
            
            const errorMessage = error instanceof Error ? error.message : 'Unknown error occurred';
            this.logger.error(`Model training failed: ${errorMessage}`);
            throw new Error(`Training failed: ${errorMessage}. Please check input data and model configuration.`);
        }
    }

    async predict(features: number[]): Promise<VulnerabilityPrediction> {
        if (!this.model) {
            throw new Error('Model not trained');
        }

        // Validate input features
        if (!features || !Array.isArray(features)) {
            throw new Error('Invalid features array provided');
        }
        
        let input: tf.Tensor2D | null = null;
        let prediction: tf.Tensor | null = null;
        let normalizedInput: tf.Tensor2D | null = null;

        try {
            // Normalize input features
            input = tf.tensor2d([features]);
            normalizedInput = tf.div(input, tf.max(input));
            
            // Get prediction
            prediction = this.model.predict(normalizedInput) as tf.Tensor;
            const values = await prediction.data();

            // Get top prediction
            const maxIndex = values.indexOf(Math.max(...values));
            const type = Object.values(VulnerabilityType)[maxIndex] || null;
            const confidence = values[maxIndex];

            return {
                type,
                confidence,
                details: this.getDetails(type, features)
            };
        } catch (error) {
            this.logger.error(`Prediction failed: ${(error as Error).message}`);
            throw new Error(`Prediction failed: ${(error as Error).message}`); 
        } finally {
            // Ensure all tensors are disposed
            if (input) input.dispose();
            if (prediction) prediction.dispose();
            if (normalizedInput) normalizedInput.dispose();
        }
    }

    private getDetails(type: VulnerabilityType | null, features: number[]): string[] {
        const details: string[] = [];
        
        if (!type) {
            return ['No significant vulnerabilities detected'];
        }

        // Feature importance mapping
        const featureMapping = {
            [VulnerabilityType.Reentrancy]: {
                index: 0,
                threshold: 0.8,
                message: 'High reentrancy risk detected'
            },
            [VulnerabilityType.ArithmeticOverflow]: {
                index: 1,
                threshold: 0.7,
                message: 'Potential arithmetic overflow detected'
            },
            [VulnerabilityType.AccessControl]: {
                index: 2,
                threshold: 0.75,
                message: 'Access control violation detected'
            },
            [VulnerabilityType.DenialOfService]: {
                index: 3,
                threshold: 0.85,
                message: 'Potential denial of service vulnerability detected'
            },
            [VulnerabilityType.LogicError]: {
                index: 4,
                threshold: 0.8,
                message: 'Logic error detected'
            },
            [VulnerabilityType.InstructionInjection]: {
                index: 5,
                threshold: 0.85,
                message: 'Instruction injection vulnerability detected'
            },
            [VulnerabilityType.AccountConfusion]: {
                index: 6,
                threshold: 0.8,
                message: 'Potential account confusion detected'
            },
            [VulnerabilityType.SignerAuthorization]: {
                index: 7,
                threshold: 0.85,
                message: 'Signer authorization issue detected'
            },
            [VulnerabilityType.PdaValidation]: {
                index: 8,
                threshold: 0.8,
                message: 'PDA validation issue detected'
            },
            [VulnerabilityType.ClockManipulation]: {
                index: 9,
                threshold: 0.85,
                message: 'Clock manipulation vulnerability detected'
            },
            [VulnerabilityType.CrossProgramInvocation]: {
                index: 10,
                threshold: 0.85,
                message: 'Cross-program invocation vulnerability detected'
            },
            [VulnerabilityType.RentExemption]: {
                index: 11,
                threshold: 0.8,
                message: 'Rent exemption issue detected'
            }
        };

        const typeDetails = type ? featureMapping[type] : undefined;
        if (typeDetails && features[typeDetails.index] > typeDetails.threshold) {
            details.push(typeDetails.message);
        }

        // Add general security recommendations
        details.push('Recommendations:');
        details.push('- Review program instructions for potential vulnerabilities');
        details.push('- Implement proper access control checks');
        details.push('- Validate all account inputs');
        details.push('- Use safe arithmetic operations');
        details.push('- Test with different input scenarios');

        return details;
    }

    async save(path: string): Promise<void> {
        if (!this.model) {
            throw new Error('Model not trained');
        }
        
        if (!path || typeof path !== 'string') {
            throw new Error('Invalid save path specified');
        }

        try {
            await this.model.save(`file://${path}`);
            this.logger.info(`Model saved successfully to ${path}`);
        } catch (error) {
            const errorMessage = error instanceof Error ? error.message : 'Unknown error';
            throw new Error(`Failed to save model: ${errorMessage}`);
        }
    }

    async load(path: string): Promise<void> {
        if (!path || typeof path !== 'string') {
            throw new Error('Invalid model path specified');
        }

        try {
            // Cleanup existing model if any
            if (this.model) {
                this.model.dispose();
            }

            this.model = await tf.loadLayersModel(`file://${path}/model.json`);
            
            // Validate loaded model structure
            if (!this.model || !this.model.inputs || !this.model.inputs[0]) {
                throw new Error('Invalid model structure detected after load');
            }

            this.logger.info(`Model loaded successfully from ${path}`);
        } catch (error) {
            const errorMessage = error instanceof Error ? error.message : 'Unknown error';
            throw new Error(`Failed to load model: ${errorMessage}`);
        }
    }

    async cleanup(): Promise<void> {
        try {
            // Dispose model and layers
            if (this.model) {
                // Dispose each layer
                this.model.layers.forEach(layer => {
                    if (layer.weights) {
                        layer.weights.forEach(w => w.dispose());
                    }
                });
                
                // Dispose model
                this.model.dispose();
                this.model = null;
            }
            
            // Dispose any remaining variables and tensors
            await tf.disposeVariables();
            
            // Force garbage collection of tensors
            const backend = tf.getBackend();
            if (backend === 'webgl') {
                const gl = await tf.backend().getGPGPUContext().gl;
                gl.getExtension('WEBGL_lose_context')?.loseContext();
            }
            
            this.logger.info('Model cleanup completed successfully');
        } catch (error) {
            const errorMessage = error instanceof Error ? error.message : 'Unknown error during cleanup';
            this.logger.error(`Cleanup failed: ${errorMessage}`);
            throw new Error(`Cleanup failed: ${errorMessage}`);
        }
        
        // Verify cleanup
        if (tf.memory().numTensors > 0) {
            this.logger.warn(`${tf.memory().numTensors} tensors still in memory after cleanup`);
        }
    }
}
