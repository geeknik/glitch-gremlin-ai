import * as tf from '@tensorflow/tfjs-node';
import { EventEmitter } from 'events';
import { Logger } from '../utils/logger.js';

export enum VulnerabilityType {
    Reentrancy = 'REENTRANCY',
    ArithmeticOverflow = 'ARITHMETIC_OVERFLOW',
    AccessControl = 'ACCESS_CONTROL',
    DenialOfService = 'DENIAL_OF_SERVICE',
    LogicError = 'LOGIC_ERROR',
    InstructionInjection = 'INSTRUCTION_INJECTION',
    AccountConfusion = 'ACCOUNT_CONFUSION',
    SignerAuthorization = 'SIGNER_AUTHORIZATION',
    PdaValidation = 'PDA_VALIDATION',
    ClockManipulation = 'CLOCK_MANIPULATION',
    CrossProgramInvocation = 'CROSS_PROGRAM_INVOCATION',
    RentExemption = 'RENT_EXEMPTION'
}

export interface VulnerabilityPrediction {
    type: VulnerabilityType | null;
    confidence: number;
    details: string[];
}

export class VulnerabilityDetectionModel extends EventEmitter {
    private model: tf.LayersModel | null = null;
    private logger: Logger;
    private attentionLayer: tf.layers.Layer | null = null;

    constructor() {
        super();
        this.logger = new Logger('VulnerabilityDetection');
    }

    async train(data: { features: number[]; vulnerabilityType: VulnerabilityType }[]) {
        this.emit('trainingStart');
        this.logger.info('Starting model training');
        if (!data || data.length === 0) {
            throw new Error('Training data cannot be empty');
        }

        try {
            // Convert data to tensors
            const features = data.map(d => d.features);
            const labels = data.map(d => d.vulnerabilityType);

            // Normalize features
            const xs = tf.tensor2d(features);
            const normalizedXs = tf.div(xs, tf.max(xs));

            // One-hot encode labels
            const ys = tf.oneHot(
                tf.tensor1d(labels, 'int32'), 
                Object.keys(VulnerabilityType).length
            );

            // Enhanced model architecture with attention
            const model = tf.sequential();
            
            // Input layer with batch normalization
            model.add(tf.layers.dense({
                units: 128,
                activation: 'relu',
                inputShape: [features[0].length],
                kernelRegularizer: tf.regularizers.l2({ l2: 0.01 })
            }));
            model.add(tf.layers.batchNormalization());
            
            // Attention mechanism
            const attention = (tf.layers as any).multiHeadAttention({
                useScale: true,
                causal: false
            });
            this.attentionLayer = attention;
            model.add(attention);
            
            // Bi-directional LSTM layer
            model.add(tf.layers.bidirectional({
                layer: tf.layers.lstm({
                    units: 64,
                    returnSequences: false
                })
            }));
            
            // Dense layers with dropout
            model.add(tf.layers.dropout({ rate: 0.3 }));
            model.add(tf.layers.dense({
                units: 64,
                activation: 'relu',
                kernelRegularizer: tf.regularizers.l2({ l2: 0.01 })
            }));
            
            model.add(tf.layers.dropout({ rate: 0.3 }));
            model.add(tf.layers.dense({
                units: 32,
                activation: 'relu'
            }));

            // Output layer with temperature scaling
            model.add(tf.layers.dense({
                units: Object.keys(VulnerabilityType).length,
                activation: 'softmax',
                kernelInitializer: 'glorotUniform',
                biasInitializer: 'zeros'
            }));

            // Compile with custom optimizer and metrics
            const optimizer = tf.train.adam(0.001, 0.9, 0.999, 1e-7);
            model.compile({
                optimizer,
                loss: 'categoricalCrossentropy',
                metrics: [
                    'accuracy',
                    'accuracy'
                ]
            });

            // Enhanced training with more callbacks
            const history = await model.fit(normalizedXs, ys, {
                epochs: 100,
                batchSize: 64,
                validationSplit: 0.2,
                callbacks: [
                    tf.callbacks.earlyStopping({
                        monitor: 'val_loss',
                        patience: 10,
                        restoreBestWeights: true,
                        verbose: 1
                    }),
                    (tf.callbacks as any).tensorBoard('./logs'),
                    {
                        onEpochEnd: async (epoch, logs) => {
                            this.emit('epochEnd', { epoch, logs });
                            this.logger.info(`Epoch ${epoch} - loss: ${logs?.loss}, val_loss: ${logs?.val_loss}`);
                        }
                    }
                ]
            });

            // Evaluate model
            const evaluation = model.evaluate(normalizedXs, ys);
            if (Array.isArray(evaluation)) {
                const [loss, accuracy, precision, recall, auc, f1] = evaluation;
                this.logger.info(`Training complete - Loss: ${loss}, Accuracy: ${accuracy}`);
                this.logger.info(`Precision: ${precision}, Recall: ${recall}`);
                this.logger.info(`AUC: ${auc}, F1: ${f1}`);
            }

            this.model = model;

            // Clean up tensors
            xs.dispose();
            normalizedXs.dispose();
            ys.dispose();
        } catch (error) {
            throw new Error(`Training failed: ${(error as Error).message}`);
        }
    }

    async predict(features: number[]): Promise<VulnerabilityPrediction> {
        if (!this.model) {
            throw new Error('Model not trained');
        }

        try {
            const input = tf.tensor2d([features]);
            const prediction = this.model.predict(input) as tf.Tensor;
            const values = await prediction.data();

            // Get top prediction with attention weights
            const maxIndex = values.indexOf(Math.max(...values));
            const type = Object.values(VulnerabilityType)[maxIndex] || null;
            const confidence = values[maxIndex];

            // Get attention weights if available
            let attentionWeights: number[] = [];
            if (this.attentionLayer) {
                const attentionOutput = this.attentionLayer.getOutputAt(0) as tf.Tensor;
                attentionWeights = await attentionOutput.data() as number[];
                tf.dispose(attentionOutput);
            }

            // Clean up tensors
            input.dispose();
            tf.dispose(prediction);

            return {
                type,
                confidence,
                details: this.getDetails(type, features),
                attentionWeights
            };
        } catch (error) {
            this.logger.error(`Prediction failed: ${(error as Error).message}`);
            throw new Error(`Prediction failed: ${(error as Error).message}`);
        }
    }

    private getDetails(type: VulnerabilityType | null, features: number[]): string[] {
        const details: string[] = [];
        
        if (!type) {
            return ['No significant vulnerabilities detected'];
        }

        // Feature importance mapping
        const featureMapping = {
            [VulnerabilityType.Reentrancy]: {
                index: 0,
                threshold: 0.8,
                message: 'High reentrancy risk detected'
            },
            [VulnerabilityType.ArithmeticOverflow]: {
                index: 1,
                threshold: 0.7,
                message: 'Potential arithmetic overflow detected'
            },
            [VulnerabilityType.AccessControl]: {
                index: 2,
                threshold: 0.75,
                message: 'Access control violation detected'
            },
            [VulnerabilityType.InstructionInjection]: {
                index: 3,
                threshold: 0.85,
                message: 'Instruction injection vulnerability detected'
            },
            [VulnerabilityType.AccountConfusion]: {
                index: 4,
                threshold: 0.8,
                message: 'Potential account confusion detected'
            }
        };

        const typeDetails = featureMapping[type];
        if (typeDetails && features[typeDetails.index] > typeDetails.threshold) {
            details.push(typeDetails.message);
        }

        // Add general security recommendations
        details.push('Recommendations:');
        details.push('- Review program instructions for potential vulnerabilities');
        details.push('- Implement proper access control checks');
        details.push('- Validate all account inputs');
        details.push('- Use safe arithmetic operations');
        details.push('- Test with different input scenarios');

        return details;
    }

    async save(path: string) {
        if (!this.model) {
            throw new Error('Model not trained');
        }
        await this.model.save(`file://${path}`);
    }

    async load(path: string) {
        this.model = await tf.loadLayersModel(`file://${path}/model.json`);
    }

    async cleanup() {
        if (this.model) {
            this.model.dispose();
        }
        await tf.disposeVariables();
    }
}
